{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from typing_extensions import Literal\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AnyMessage, ToolMessage\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableLambda, RunnableBranch\n",
    "from langchain_core.tools import tool, StructuredTool\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from typing import Dict, Any, List, Optional\n",
    "from langsmith import traceable\n",
    "from tavily import TavilyClient\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from dataclasses import dataclass, fields, field\n",
    "import json\n",
    "from typing_extensions import TypedDict, Annotated, Literal\n",
    "import operator\n",
    "from IPython.display import Markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name = 'Gemma2-9b-it', api_key = os.getenv('GROQ_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_writer_instruction_web = \"\"\"Your goal is to generate a targeted web search query related to financial investments or any finance-related topic specified by the user.\n",
    "\n",
    "<TOPIC>\n",
    "{finance_topic}\n",
    "</TOPIC>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with ALL three of these exact keys:\n",
    "   - \"query\": The actual search query string\n",
    "   - \"aspect\": The specific aspect of the finance topic being researched\n",
    "   - \"rationale\": Brief explanation of why this query is relevant\n",
    "</FORMAT>\n",
    "\n",
    "<EXAMPLE>\n",
    "Example output:\n",
    "{{\n",
    "    \"query\": \"best index funds for long-term investment 2025\",\n",
    "    \"aspect\": \"investment strategy\",\n",
    "    \"rationale\": \"Identifying top-performing index funds for long-term portfolio growth\"\n",
    "}}\n",
    "</EXAMPLE>\n",
    "\n",
    "Provide your response in JSON format:\n",
    "\"\"\"\n",
    "\n",
    "summarizer_instruction_web = \"\"\"<GOAL>\n",
    "Generate a high-quality summary of the web search results, focusing on financial investments or the specific finance-related topic requested by the user.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "When creating a NEW summary:\n",
    "1. Highlight the most relevant financial insights, trends, or strategies from the search results.\n",
    "2. Ensure a coherent flow of information while keeping it concise and actionable.\n",
    "\n",
    "When EXTENDING an existing summary:\n",
    "1. Read the existing summary and new search results carefully.\n",
    "2. Compare the new information with the existing summary.\n",
    "3. For each piece of new information:\n",
    "    a. If it builds on an existing point, integrate it smoothly.\n",
    "    b. If it introduces a new relevant aspect, add a separate paragraph.\n",
    "    c. If it’s irrelevant to financial investments, ignore it.\n",
    "4. Ensure all additions align with the user’s finance-related query.\n",
    "5. Verify that the final output differs from the original summary while improving its depth.\n",
    "\n",
    "<FORMATTING>\n",
    "- Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.\n",
    "</FORMATTING>\n",
    "\"\"\"\n",
    "\n",
    "reflection_instructions_web = \"\"\"You are an expert financial research assistant analyzing a summary about {finance_topic}.\n",
    "\n",
    "<GOAL>\n",
    "1. Identify missing details or areas that need deeper exploration.\n",
    "2. Generate a follow-up question to help expand financial knowledge.\n",
    "3. Focus on investment strategies, market trends, risk factors, regulations, or financial instruments that weren’t fully covered.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "Ensure the follow-up question is self-contained and provides necessary context for a web search.\n",
    "</REQUIREMENTS>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with these exact keys:\n",
    "- \"knowledge_gap\": Describe what financial information is missing or unclear.\n",
    "- \"follow_up_query\": Write a specific question to address this gap.\n",
    "</FORMAT>\n",
    "\n",
    "<EXAMPLE>\n",
    "Example output:\n",
    "{{\n",
    "    \"knowledge_gap\": \"The summary does not mention tax implications of investing in ETFs vs. mutual funds.\",\n",
    "    \"follow_up_query\": \"What are the tax advantages and disadvantages of ETFs compared to mutual funds?\"\n",
    "}}\n",
    "</EXAMPLE>\n",
    "\n",
    "Provide your analysis in JSON format:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    route: Literal['Web_query', 'Normal_query', 'Financial_Analysis'] = Field(None)\n",
    "    research_topic: str = \"\"\n",
    "    search_query: str = \"\"\n",
    "    web_research_results: Annotated[list, operator.add] = []\n",
    "    sources_gathered: Annotated[list, operator.add] = []\n",
    "    research_loop_count: int = 0\n",
    "    running_summary: str = \"\"\n",
    "    messages: Annotated[list, operator.add] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_state(user_query: str):\n",
    "    return {\n",
    "        \"route\": None,\n",
    "        \"research_topic\": user_query,\n",
    "        \"search_query\": \"\",\n",
    "        \"web_research_results\": [],\n",
    "        \"sources_gathered\": [],\n",
    "        \"research_loop_count\": 0,\n",
    "        \"running_summary\": \"\",\n",
    "        \"messages\": [HumanMessage(content=user_query)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Routing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Route_First_Step(BaseModel):\n",
    "    step: Literal['Web_query', 'Normal_query', 'Financial_Analysis'] = Field(None, description = 'Given the query, determine whether to perform a web search, answer a normal question(like a definition), or perform a financial analysis(for which you have tools).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAPI(Enum):\n",
    "    PERPLEXITY = \"perplexity\"\n",
    "    TAVILY = \"tavily\"\n",
    "    DUCKDUCKGO = \"duckduckgo\"\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Configuration:\n",
    "    \"\"\"The configurable fields for the research assistant.\"\"\"\n",
    "    max_web_research_loops: int = int(os.environ.get(\"MAX_WEB_RESEARCH_LOOPS\", \"3\"))\n",
    "    #local_llm: str = llm\n",
    "    search_api: SearchAPI = SearchAPI(os.environ.get(\"SEARCH_API\", SearchAPI.TAVILY.value))  # Default to DUCKDUCKGO\n",
    "    fetch_full_page: bool = os.environ.get(\"FETCH_FULL_PAGE\", \"False\").lower() in (\"true\", \"1\", \"t\")\n",
    "    ollama_base_url: str = os.environ.get(\"OLLAMA_BASE_URL\", \"http://localhost:11434/\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[RunnableConfig] = None\n",
    "    ) -> \"Configuration\":\n",
    "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
    "        configurable = (\n",
    "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        )\n",
    "        values: dict[str, Any] = {\n",
    "            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))\n",
    "            for f in fields(cls)\n",
    "            if f.init\n",
    "        }\n",
    "        return cls(**{k: v for k, v in values.items() if v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable\n",
    "def tavily_search(query, include_raw_content=True, max_results=3):\n",
    "    \"\"\" Search the web using the Tavily API.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        include_raw_content (bool): Whether to include the raw_content from Tavily in the formatted string\n",
    "        max_results (int): Maximum number of results to return\n",
    "\n",
    "    Returns:\n",
    "        dict: Search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result\n",
    "                - url (str): URL of the search result\n",
    "                - content (str): Snippet/summary of the content\n",
    "                - raw_content (str): Full content of the page if available\"\"\"\n",
    "\n",
    "    api_key = os.environ['TAVILY_API_KEY']\n",
    "    if not api_key:\n",
    "        raise ValueError(\"TAVILY_API_KEY environment variable is not set\")\n",
    "    tavily_client = TavilyClient(api_key=api_key)\n",
    "    return tavily_client.search(query,\n",
    "                         max_results=max_results,\n",
    "                         include_raw_content=include_raw_content)\n",
    "\n",
    "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=False):\n",
    "    \"\"\"\n",
    "    Takes either a single search response or list of responses from search APIs and formats them.\n",
    "    Limits the raw_content to approximately max_tokens_per_source.\n",
    "    include_raw_content specifies whether to include the raw_content from Tavily in the formatted string.\n",
    "\n",
    "    Args:\n",
    "        search_response: Either:\n",
    "            - A dict with a 'results' key containing a list of search results\n",
    "            - A list of dicts, each containing search results\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted string with deduplicated sources\n",
    "    \"\"\"\n",
    "    # Convert input to list of results\n",
    "    if isinstance(search_response, dict):\n",
    "        sources_list = search_response['results']\n",
    "    elif isinstance(search_response, list):\n",
    "        sources_list = []\n",
    "        for response in search_response:\n",
    "            if isinstance(response, dict) and 'results' in response:\n",
    "                sources_list.extend(response['results'])\n",
    "            else:\n",
    "                sources_list.extend(response)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
    "\n",
    "    # Deduplicate by URL\n",
    "    unique_sources = {}\n",
    "    for source in sources_list:\n",
    "        if source['url'] not in unique_sources:\n",
    "            unique_sources[source['url']] = source\n",
    "\n",
    "    # Format output\n",
    "    formatted_text = \"Sources:\\n\\n\"\n",
    "    for i, source in enumerate(unique_sources.values(), 1):\n",
    "        formatted_text += f\"Source {source['title']}:\\n===\\n\"\n",
    "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
    "        if include_raw_content:\n",
    "            # Using rough estimate of 4 characters per token\n",
    "            char_limit = max_tokens_per_source * 4\n",
    "            # Handle None raw_content\n",
    "            raw_content = source.get('raw_content', '')\n",
    "            if raw_content is None:\n",
    "                raw_content = ''\n",
    "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
    "\n",
    "    return formatted_text.strip()\n",
    "\n",
    "def format_sources(search_results):\n",
    "    \"\"\"Format search results into a bullet-point list of sources.\n",
    "\n",
    "    Args:\n",
    "        search_results (dict): Tavily search response containing results\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted string with sources and their URLs\n",
    "    \"\"\"\n",
    "    return '\\n'.join(\n",
    "        f\"* {source['title']} : {source['url']}\"\n",
    "        for source in search_results['results']\n",
    "    )\n",
    "\n",
    "def generate_query(state: State, config: RunnableConfig):\n",
    "    \"\"\"Generate a query for web search.\"\"\"\n",
    "    # Format the prompt using the correct placeholder\n",
    "    query_writer_instruction_web_formatted = query_writer_instruction_web.format(finance_topic=state[\"research_topic\"])\n",
    "    prompt = query_writer_instruction_web_formatted + \"\\nGenerate a query for web search:\"\n",
    "\n",
    "    result = llm.invoke(prompt)\n",
    "    output_text = result.content.strip()\n",
    "    try:\n",
    "        query = json.loads(output_text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not decode JSON from generate_query. Response was:\", output_text)\n",
    "        # Fallback: Return a default query\n",
    "        query = {\"query\": f\"Tell me more about {state['research_topic']}\", \"aspect\": \"\", \"rationale\": \"\"}\n",
    "    return {\"search_query\": query['query']}\n",
    "\n",
    "\n",
    "def web_research(state: State, config: RunnableConfig):\n",
    "    \"\"\"Gather information from the web.\"\"\"\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Determine which search API to use\n",
    "    if isinstance(configurable.search_api, str):\n",
    "        search_api = configurable.search_api\n",
    "    else:\n",
    "        search_api = configurable.search_api.value\n",
    "\n",
    "    if search_api == \"tavily\":\n",
    "        search_results = tavily_search(state[\"search_query\"], include_raw_content=True, max_results=1)\n",
    "        search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported search API: {configurable.search_api}\")\n",
    "\n",
    "    return {\n",
    "        \"sources_gathered\": [format_sources(search_results)],\n",
    "        \"research_loop_count\": state[\"research_loop_count\"] + 1,\n",
    "        \"web_research_results\": [search_str]\n",
    "    }\n",
    "\n",
    "\n",
    "def summarize_sources(state: State, config: RunnableConfig):\n",
    "    \"\"\"Summarize the gathered sources.\"\"\"\n",
    "    # Existing summary and most recent search results\n",
    "    existing_summary = state['running_summary']\n",
    "    most_recent_web_research = state['web_research_results'][-1]\n",
    "\n",
    "    if existing_summary:\n",
    "        human_message_content = (\n",
    "            f\"<User Input> \\n {state['research_topic']} \\n <User Input>\\n\\n\"\n",
    "            f\"<Existing Summary> \\n {existing_summary} \\n <Existing Summary>\\n\\n\"\n",
    "            f\"<New Search Results> \\n {most_recent_web_research} \\n <New Search Results>\"\n",
    "        )\n",
    "    else:\n",
    "        human_message_content = (\n",
    "            f\"<User Input> \\n {state['research_topic']} \\n <User Input>\\n\\n\"\n",
    "            f\"<Search Results> \\n {most_recent_web_research} \\n <Search Results>\"\n",
    "        )\n",
    "\n",
    "    prompt = summarizer_instruction_web + \"\\n\" + human_message_content\n",
    "\n",
    "    result = llm.invoke(prompt)\n",
    "    running_summary = result.content\n",
    "\n",
    "    # Remove any unwanted <think> tags\n",
    "    while \"<think>\" in running_summary and \"</think>\" in running_summary:\n",
    "        start = running_summary.find(\"<think>\")\n",
    "        end = running_summary.find(\"</think>\") + len(\"</think>\")\n",
    "        running_summary = running_summary[:start] + running_summary[end:]\n",
    "\n",
    "    return {\"running_summary\": running_summary}\n",
    "\n",
    "def reflect_on_summary(state: State, config: RunnableConfig):\n",
    "    \"\"\"Reflect on the summary and generate a follow-up query.\"\"\"\n",
    "    prompt = (\n",
    "        reflection_instructions_web.format(finance_topic=state['research_topic'])\n",
    "        + \"\\nIdentify a knowledge gap and generate a follow-up web search query based on our existing knowledge: \"\n",
    "        + state['running_summary']\n",
    "    )\n",
    "\n",
    "    result = llm.invoke(prompt)\n",
    "    \n",
    "    output_text = result.content.strip()\n",
    "    try:\n",
    "        follow_up_query = json.loads(output_text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not decode JSON from reflect_on_summary. Response was:\", output_text)\n",
    "        # Fallback: Return a default follow-up query\n",
    "        follow_up_query = {\"follow_up_query\": f\"Tell me more about {state['research_topic']}\"}\n",
    "\n",
    "    query = follow_up_query.get('follow_up_query')\n",
    "    if not query:\n",
    "        return {\"search_query\": f\"Tell me more about {state['research_topic']}\"}\n",
    "    return {\"search_query\": query}\n",
    "\n",
    "\n",
    "def finalize_summary(state: State):\n",
    "    \"\"\"Finalize the summary by aggregating all source information.\"\"\"\n",
    "    all_sources = \"\\n\".join(source for source in state['sources_gathered'])\n",
    "    state['running_summary'] = f\"## Summary\\n\\n{state['running_summary']}\\n\\n### Sources:\\n{all_sources}\"\n",
    "    return {\"running_summary\": state['running_summary']}\n",
    "\n",
    "def route_research(state: State, config: RunnableConfig) -> Literal[\"finalize_summary\", \"web_research\"]:\n",
    "    \"\"\"Route the research based on the follow-up query.\"\"\"\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    if state['research_loop_count'] <= configurable.max_web_research_loops:\n",
    "        return \"web_research\"\n",
    "    else:\n",
    "        return \"finalize_summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "router = llm.with_structured_output(Route_First_Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_route_first_step(state: State):\n",
    "    \n",
    "    # Make the routing decision\n",
    "    decision = router.invoke(state[\"research_topic\"])\n",
    "    \n",
    "    # Update the state with the route and research_topic\n",
    "    return {\n",
    "        \"route\": decision.step,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_state_transition(old_state: State, new_state: State):\n",
    "    required_fields = set(State.__annotations__.keys())\n",
    "    missing = required_fields - set(new_state.keys())\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing state updates for: {missing}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool, StructuredTool\n",
    "import yfinance as yf\n",
    "\n",
    "@tool\n",
    "def company_address(ticker: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns company address for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns company address for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return \" \".join([info[key] for key in ['address1','city','state','zip','country']])\n",
    "\n",
    "@tool\n",
    "def fulltime_employees(ticker: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns fulltime employees count for input ticker.\n",
    "    e.g. company_address: MSFT\n",
    "    Returns fulltime employees count for ticker MSFT which is stock ticker for Microsoft.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['fullTimeEmployees']\n",
    "\n",
    "@tool\n",
    "def last_close_price(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns last close price for input ticker.\n",
    "    e.g. company_address: MSFT\n",
    "    Returns last close price for ticker MSFT which is stock ticker for Microsoft.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['previousClose']\n",
    "\n",
    "@tool\n",
    "def EBITDA(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns EBITDA for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns EBITDA for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['ebitda']\n",
    "\n",
    "@tool\n",
    "def total_debt(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns total debt for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns total debt for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['totalDebt']\n",
    "\n",
    "@tool\n",
    "def total_revenue(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns total revenue for input ticker.\n",
    "    e.g. company_address: MSFT\n",
    "    Returns total revenue for ticker MSFT which is stock ticker for Microsoft.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['totalRevenue']\n",
    "\n",
    "@tool\n",
    "def debt_to_equity_ratio(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns debt to equity ratio for input ticker.\n",
    "    e.g. company_address: AAPL\n",
    "    Returns debt to equity ratio for ticker AAPL which is stock ticker for Apple Inc.\n",
    "    \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.get_info()\n",
    "\n",
    "    return info['debtToEquity']\n",
    "\n",
    "finance_tools = [\n",
    "    company_address,\n",
    "    fulltime_employees,\n",
    "    last_close_price,\n",
    "    EBITDA,\n",
    "    total_debt,\n",
    "    total_revenue,\n",
    "    debt_to_equity_ratio\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_normal = llm\n",
    "normal_query_prompt = \"\"\"\n",
    "You are a financial analyst. Please answer the user's question based on what you know, don't make up anything.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_normal_query(state: State):\n",
    "    messages = state.get('query', [])\n",
    "    messages = [SystemMessage(content=normal_query_prompt)] + messages\n",
    "    message = llm_normal.invoke(messages)\n",
    "    return {\"message\": [message]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_financial_analysis = llm.bind_tools(finance_tools, tool_choice = 'auto')\n",
    "financial_analysis_prompt = \"\"\"\n",
    "You are a financial analyst. You are given tools for acurate data\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(state: State):\n",
    "    messages = state['messages']\n",
    "    if financial_analysis_prompt:\n",
    "        messages = [SystemMessage(content=financial_analysis_prompt)] + messages\n",
    "    message = llm_financial_analysis.invoke(messages)\n",
    "    return {'messages': [message]}\n",
    "\n",
    "def exists_action(state: State):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "def take_action(state: State):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling Tool : {t}\")\n",
    "            if not t['name'] in finance_tools:\n",
    "                print(f\"\\n Tool : {t} does not exist.\")\n",
    "                result = \"Incorrect Tool Name, Please retry and select tool from available tools.\"\n",
    "            else:\n",
    "                result = finance_tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id = t['id'], name = t['name'], content = str(result)))\n",
    "        print(\"Tool execution is completed. Back to the model!\")\n",
    "        return {'messages' : results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Route Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_route(state: State) -> str:\n",
    "    return state[\"route\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1d9dd143810>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_router = StateGraph(State)\n",
    "final_router.add_node(\"route_first_step\", call_route_first_step)\n",
    "\n",
    "final_router.add_node(\"generate_query\", generate_query)\n",
    "final_router.add_node(\"web_research\", web_research)\n",
    "final_router.add_node(\"summarize_sources\", summarize_sources)\n",
    "final_router.add_node(\"reflect_on_summary\", reflect_on_summary)\n",
    "final_router.add_node(\"finalize_summary\", finalize_summary)\n",
    "final_router.add_node('call_llm', call_llm)\n",
    "final_router.add_node('take_action', take_action)\n",
    "final_router.add_node('answer_normal_query', answer_normal_query)\n",
    "final_router.add_edge(START, \"route_first_step\")\n",
    "final_router.add_conditional_edges(\"route_first_step\", get_route, {\n",
    "    'Web_query': 'generate_query',\n",
    "    'Normal_query': 'answer_normal_query',\n",
    "    'Financial_Analysis': 'call_llm'\n",
    "})\n",
    "\n",
    "final_router.add_edge(\"answer_normal_query\", END)\n",
    "final_router.add_conditional_edges(\n",
    "            \"call_llm\",\n",
    "            exists_action,\n",
    "            {True: \"take_action\", False: END}\n",
    "        )\n",
    "final_router.add_edge(\"take_action\", \"call_llm\")\n",
    "\n",
    "final_router.add_edge(\"generate_query\", \"web_research\")\n",
    "final_router.add_edge(\"web_research\", \"summarize_sources\")\n",
    "final_router.add_edge(\"summarize_sources\", \"reflect_on_summary\")\n",
    "final_router.add_conditional_edges(\"reflect_on_summary\", route_research)\n",
    "final_router.add_edge(\"finalize_summary\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = final_router.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"query\": \"What does stock mean?\",\n",
    "    \"route\": None,\n",
    "    \"research_topic\": \"What does stock mean?\",\n",
    "    \"search_query\": \"What does stock mean?\",\n",
    "    \"web_research_results\": [],\n",
    "    \"sources_gathered\": [],\n",
    "    \"research_loop_count\": 0,\n",
    "    \"running_summary\": \"\",\n",
    "    \"message\": []\n",
    "}\n",
    "normal_query = final_model.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not decode JSON from generate_query. Response was: ```json\n",
      "{\n",
      "    \"query\": \"us presidential election 2024\",\n",
      "    \"aspect\": \"political landscape\",\n",
      "    \"rationale\": \"The outcome of the 2024 election will likely influence financial markets and economic policy, making it relevant to financial considerations.\" \n",
      "}\n",
      "```\n",
      "Warning: No raw_content found for source https://www.advisorperspectives.com/commentaries/2025/01/19/reviewing-economic-market-performance-during-biden-administration\n",
      "Error: Could not decode JSON from reflect_on_summary. Response was: ```json\n",
      "{\n",
      "    \"knowledge_gap\": \"The summary mentions Biden's presidency has been characterized by a resilient economy and strong corporate fundamentals leading to equity gains, but it doesn't specify the potential impact of these factors on specific investment sectors.\",\n",
      "    \"follow_up_query\": \"How have sectors like technology, healthcare, and energy performed during President Biden's term, and what are the forecasts for their future performance based on current economic trends?\"\n",
      "}\n",
      "```\n",
      "Error: Could not decode JSON from reflect_on_summary. Response was: ```json\n",
      "{\n",
      "    \"knowledge_gap\": \"While the summary mentions Biden's presidency leading to economic resilience and strong equity performance, it doesn't specify how his economic policies might influence specific sectors or investment strategies in the future.\",\n",
      "    \"follow_up_query\": \"How are financial analysts predicting the impact of President Biden's economic policies on sectors like renewable energy, healthcare, or technology in the next few years?\"\n",
      "}\n",
      "```\n",
      "Error: Could not decode JSON from reflect_on_summary. Response was: ```json\n",
      "{\n",
      "    \"knowledge_gap\": \"While the summary mentions Biden's presidency has led to a resilient economy and positive returns in risk assets, it doesn't specify the potential impact of his policies on specific financial instruments or sectors.\",\n",
      "    \"follow_up_query\": \"How have specific Biden administration policies, such as infrastructure spending or climate change initiatives, influenced investments in sectors like renewable energy, technology, or construction?\"\n",
      "}\n",
      "```\n",
      "Final state validated successfully!\n",
      "Summary: ## Summary\n",
      "\n",
      "The President of the United States in 2025 will be Joseph R. Biden. He is the 46th President and assumed office on January 20, 2021.  According to financial analysts, Biden's presidency has been characterized by a resilient economy, leading to solid performance in risk assets.  Despite this, inflation has pushed bond yields higher.  The strong economy and corporate fundamentals have also contributed to significant equity gains during his term.  \n",
      "\n",
      "\n",
      "\n",
      "### Sources:\n",
      "* President in 2025 : https://whowaspresident.com/2025\n",
      "* Reviewing Market and Economic Performance During the Biden ... : https://www.advisorperspectives.com/commentaries/2025/01/19/reviewing-economic-market-performance-during-biden-administration\n",
      "* President in 2025 : https://whowaspresident.com/2025\n",
      "* President in 2025 : https://whowaspresident.com/2025\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize with proper state structure\n",
    "    initial_state = create_initial_state(\"who is the president of the united states in 2025, use web search to find the answer?\")\n",
    "    \n",
    "    # Execute workflow\n",
    "    result = final_model.invoke(initial_state)\n",
    "    \n",
    "    # Validate final state\n",
    "    validate_state_transition(initial_state, result)\n",
    "    print(\"Final state validated successfully!\")\n",
    "    print(\"Summary:\", result[\"running_summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'route': 'Normal_query',\n",
       " 'research_topic': 'who is the president of the united states in 2025?',\n",
       " 'search_query': '',\n",
       " 'web_research_results': [],\n",
       " 'sources_gathered': [],\n",
       " 'research_loop_count': 0,\n",
       " 'running_summary': '',\n",
       " 'messages': [HumanMessage(content='who is the president of the united states in 2025?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='who is the president of the united states in 2025, use web search to find the answer?', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
